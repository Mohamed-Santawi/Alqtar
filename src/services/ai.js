/**
 * AIML API Service
 * Provides integration with AIML API for AI-powered features
 */

const API_URL =
  import.meta.env.VITE_AIML_API_URL || "https://api.aimlapi.com/v1";
const API_KEY =
  import.meta.env.VITE_AIML_API_KEY || "24846e8f3bce499aaf46ae76bb75f388";

/**
 * Make a chat completion request
 * @param {Array} messages - Array of message objects with role and content
 * @param {Object} options - Additional options like model, temperature, etc.
 */
export async function chatCompletion(messages, options = {}) {
  try {
    const response = await fetch(`${API_URL}/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${API_KEY}`,
      },
      body: JSON.stringify({
        model: options.model || "openai/gpt-5-nano-2025-08-07",
        messages,
        temperature: options.temperature || 0.7,
        max_tokens: options.maxTokens || 4096,
        ...options,
      }),
    });

    if (!response.ok) {
      let errorMessage = "AI API request failed";
      try {
        const error = await response.json();
        errorMessage = error.error?.message || error.message || errorMessage;
      } catch (e) {
        errorMessage = `HTTP ${response.status}: ${response.statusText}`;
      }
      throw new Error(errorMessage);
    }

    return response.json();
  } catch (error) {
    console.error("Error in chatCompletion:", error);
    throw error;
  }
}

/**
 * Stream chat completion for real-time responses
 * @param {Array} messages - Array of message objects
 * @param {Function} onChunk - Callback for each streamed chunk
 * @param {Object} options - Additional options
 */
export async function streamChatCompletion(messages, onChunk, options = {}) {
  const response = await fetch(`${API_URL}/chat/completions`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${API_KEY}`,
    },
    body: JSON.stringify({
      model: options.model || "openai/gpt-5-nano-2025-08-07",
      messages,
      temperature: options.temperature || 0.7,
      max_tokens: options.maxTokens || 4096,
      stream: true,
      ...options,
    }),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message || "AI API request failed");
  }

  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = "";

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split("\n");
    buffer = lines.pop() || "";

    for (const line of lines) {
      if (line.startsWith("data: ")) {
        const data = line.slice(6);
        if (data === "[DONE]") return;
        try {
          const parsed = JSON.parse(data);
          const content = parsed.choices?.[0]?.delta?.content;
          if (content) onChunk(content);
        } catch (e) {
          // Skip invalid JSON
        }
      }
    }
  }
}

/**
 * Generate an image using AI
 * @param {string} prompt - The image generation prompt
 * @param {Object} options - Additional options like size, model, etc.
 */
export async function generateImage(prompt, options = {}) {
  const response = await fetch(`${API_URL}/images/generations`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${API_KEY}`,
    },
    body: JSON.stringify({
      model: options.model || "dall-e-3",
      prompt,
      n: options.n || 1,
      size: options.size || "1024x1024",
      ...options,
    }),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message || "Image generation failed");
  }

  return response.json();
}

/**
 * Analyze an image and get description
 * @param {string} imageUrl - URL or base64 of the image
 * @param {string} prompt - What to analyze about the image
 */
export async function analyzeImage(
  imageUrl,
  prompt = "┘И╪╡┘Б ┘З╪░┘З ╪з┘Д╪╡┘И╪▒╪й ╪и╪з┘Д╪к┘Б╪╡┘К┘Д"
) {
  const messages = [
    {
      role: "user",
      content: [
        { type: "text", text: prompt },
        { type: "image_url", image_url: { url: imageUrl } },
      ],
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Generate research paper content using GPT-5 Nano
 * @param {string} topic - The research topic
 * @param {string} researcherName - Researcher name
 * @param {string} supervisorName - Supervisor name
 * @param {Array} sections - Sections to include (checked options)
 * @param {string} userMessage - Additional user instructions from chat
 * @param {Object} options - Additional options
 */
export async function generateResearchPaper(
  topic,
  researcherName = "",
  supervisorName = "",
  sections = [],
  userMessage = "",
  options = {}
) {
  // Build concise sections list
  const sectionsList =
    sections.length > 0
      ? sections.join("╪М ")
      : "╪з┘Д┘Е┘В╪п┘Е╪й╪М ┘Б┘З╪▒╪│ ╪з┘Д┘Е╪н╪к┘И┘Й╪М ╪з┘Д┘Е┘Д╪о╪╡╪М ╪з┘Д┘Е┘Ж┘З╪м┘К╪й╪М ╪з┘Д┘Ж╪к╪з╪ж╪м╪М ╪з┘Д╪о╪з╪к┘Е╪й╪М ╪з┘Д┘Е╪▒╪з╪м╪╣";

  // Build optimized prompt - concise but complete
  let userPrompt = `┘Е┘И╪╢┘И╪╣: "${topic}"\n`;
  if (researcherName) userPrompt += `╪и╪з╪н╪л: ${researcherName}\n`;
  if (supervisorName) userPrompt += `┘Е╪┤╪▒┘Б: ${supervisorName}\n`;

  // ╪к╪╣┘Д┘К┘Е╪з╪к ┘И╪з╪╢╪н╪й ┘Д┘Д╪г┘В╪│╪з┘Е ╪з┘Д┘Е╪н╪п╪п╪й ┘Б┘В╪╖
  if (sections.length > 0) {
    userPrompt += `\nтЪая╕П ┘Е┘З┘Е ╪м╪п╪з┘Л: ╪з┘Г╪к╪и ┘Б┘В╪╖ ╪з┘Д╪г┘В╪│╪з┘Е ╪з┘Д╪к╪з┘Д┘К╪й ┘И┘Д╪з ╪к┘Г╪к╪и ╪г┘К ╪г┘В╪│╪з┘Е ╪г╪о╪▒┘Й:\n${sections.join("\n")}\n\n`;
    userPrompt += `┘Е┘Е┘Ж┘И╪╣ ┘Г╪к╪з╪и╪й ╪г┘К ╪г┘В╪│╪з┘Е ╪║┘К╪▒ ╪з┘Д┘Е╪░┘Г┘И╪▒╪й ╪г╪╣┘Д╪з┘З. ╪з┘Г╪к╪и ┘Б┘В╪╖ ╪з┘Д╪г┘В╪│╪з┘Е ╪з┘Д┘Е╪н╪п╪п╪й.\n`;
    userPrompt += `тЪая╕П ┘Е┘З┘Е ╪м╪п╪з┘Л: ┘Д╪з ╪к┘Г╪▒╪▒ ╪г┘К ┘В╪│┘Е - ┘Г┘Д ┘В╪│┘Е ┘К╪м╪и ╪г┘Ж ┘К╪╕┘З╪▒ ┘Е╪▒╪й ┘И╪з╪н╪п╪й ┘Б┘В╪╖.\n`;
    userPrompt += `тЪая╕П ┘Е┘З┘Е ╪м╪п╪з┘Л: ┘Д╪з ╪к┘Г╪к╪и "┘Б┘З╪▒╪│ ╪з┘Д┘Е╪н╪к┘И┘Й" ┘Г┘В╪│┘Е ┘Б┘К ╪з┘Д┘Е╪н╪к┘И┘Й.\n`;
  } else {
    userPrompt += `╪г┘В╪│╪з┘Е: ${sectionsList}\n`;
  }

  if (userMessage) userPrompt += `\n┘Е┘Д╪з╪н╪╕╪з╪к ╪е╪╢╪з┘Б┘К╪й: ${userMessage}\n`;

  const messages = [
    {
      role: "system",
      content: `╪г┘Ж╪к ╪и╪з╪н╪л ╪г┘Г╪з╪п┘К┘Е┘К ┘Е╪к╪о╪╡╪╡. ╪з┘Г╪к╪и ╪и╪н╪л╪з┘Л ╪╣┘Д┘Е┘К╪з┘Л ┘Г╪з┘Е┘Д╪з┘Л ╪и┘Д╪║╪й ╪╣╪▒╪и┘К╪й ╪▒╪╡┘К┘Ж╪й ┘И┘Е╪╣╪з┘К┘К╪▒ ╪г┘Г╪з╪п┘К┘Е┘К╪й.

┘В┘И╪з╪╣╪п ┘Е┘З┘Е╪й ╪м╪п╪з┘Л:
- ╪з┘Г╪к╪и ╪з┘Д┘Е╪н╪к┘И┘Й ╪и╪з┘Д╪╣╪▒╪и┘К╪й ┘Б┘В╪╖
- ┘Д╪з ╪к┘Г╪к╪и ╪г┘К ╪г┘Г┘И╪з╪п LaTeX ╪г┘И HTML ╪г┘И ╪г┘К ┘Д╪║╪й ╪и╪▒┘Е╪м╪й
- ┘Д╪з ╪к┘Г╪к╪и ╪г┘К ╪к╪╣┘Д┘К┘Е╪з╪к ╪к┘Ж┘Б┘К╪░ ╪г┘И ╪е╪▒╪┤╪з╪п╪з╪к
- ┘Д╪з ╪к┘Г╪к╪и ╪г┘К ┘Е┘Д╪з╪н╪╕╪з╪к ╪к┘Е┘З┘К╪п┘К╪й ╪г┘И ╪к┘Ж╪и┘К┘З╪з╪к
- ╪з╪и╪п╪г ┘Е╪и╪з╪┤╪▒╪й ╪и╪╣┘Ж┘И╪з┘Ж ╪з┘Д╪и╪н╪л ╪л┘Е ╪з┘Д┘Е╪н╪к┘И┘Й
- ╪з╪│╪к╪о╪п┘Е ╪к┘Ж╪│┘К┘В ┘Ж╪╡┘К ╪и╪│┘К╪╖ ╪и╪з┘Д╪╣╪▒╪и┘К╪й ┘Б┘В╪╖
- ┘Д╪з ╪к╪░┘Г╪▒ ╪г┘К ╪┤┘К╪б ╪╣┘Ж ╪з┘Д╪о╪╖┘И╪╖ ╪г┘И ╪з┘Д╪г┘Д┘И╪з┘Ж ╪г┘И ╪з┘Д╪к┘Ж╪│┘К┘В
- тЪая╕П ┘Е┘З┘Е ╪м╪п╪з┘Л: ╪е╪░╪з ╪к┘Е ╪к╪н╪п┘К╪п ╪г┘В╪│╪з┘Е ┘Е╪н╪п╪п╪й ┘Б┘В╪╖╪М ╪з┘Г╪к╪и ┘Б┘В╪╖ ┘З╪░┘З ╪з┘Д╪г┘В╪│╪з┘Е ┘И┘Д╪з ╪к╪╢┘К┘Б ╪г┘К ╪г┘В╪│╪з┘Е ╪г╪о╪▒┘Й ╪║┘К╪▒ ┘Е╪░┘Г┘И╪▒╪й
- ╪з┘Д╪к╪▓┘Е ╪к┘Е╪з┘Е╪з┘Л ╪и╪з┘Д╪г┘В╪│╪з┘Е ╪з┘Д┘Е╪н╪п╪п╪й ┘Б┘К ╪з┘Д╪к╪╣┘Д┘К┘Е╪з╪к ┘И┘Д╪з ╪к╪о╪▒╪м ╪╣┘Ж┘З╪з
- тЪая╕П ┘Е┘З┘Е ╪м╪п╪з┘Л: ┘Д╪з ╪к┘Г╪▒╪▒ ╪г┘К ┘В╪│┘Е - ┘Г┘Д ┘В╪│┘Е ┘К╪м╪и ╪г┘Ж ┘К╪╕┘З╪▒ ┘Е╪▒╪й ┘И╪з╪н╪п╪й ┘Б┘В╪╖
- тЪая╕П ┘Е┘З┘Е ╪м╪п╪з┘Л: ┘Д╪з ╪к┘Г╪к╪и "┘Б┘З╪▒╪│ ╪з┘Д┘Е╪н╪к┘И┘Й" ┘Г┘В╪│┘Е ┘Б┘К ╪з┘Д┘Е╪н╪к┘И┘Й - ╪з┘Д┘Б┘З╪▒╪│ ╪│┘К╪к┘Е ╪е╪╢╪з┘Б╪к┘З ╪к┘Д┘В╪з╪ж┘К╪з┘Л`,
    },
    {
      role: "user",
      content: userPrompt,
    },
  ];

  const response = await chatCompletion(messages, {
    model: options.model || "openai/gpt-5-nano-2025-08-07",
    maxTokens: options.maxTokens || 8000, // Reduced from 12000 for efficiency
    temperature: options.temperature || 0.7,
  });

  // Log token usage for monitoring
  if (response.usage) {
    console.log("ЁЯУК Token Usage:", {
      prompt: response.usage.prompt_tokens,
      completion: response.usage.completion_tokens,
      total: response.usage.total_tokens,
      cost: `${(response.usage.total_tokens * 0.000001).toFixed(6)} credits`, // Approximate
    });
  }

  return response;
}

/**
 * Generate questions from content
 * @param {string} content - The content to generate questions from
 * @param {Object} options - Question generation options
 */
export async function generateQuestions(content, options = {}) {
  const questionTypes = options.types || [
    "╪з╪о╪к┘К╪з╪▒ ┘Е┘Ж ┘Е╪к╪╣╪п╪п",
    "╪╡╪н ┘И╪о╪╖╪г",
    "╪г╪│╪ж┘Д╪й ┘Е┘В╪з┘Д┘К╪й",
  ];
  const count = options.count || 10;

  const messages = [
    {
      role: "system",
      content: `╪г┘Ж╪к ┘Е╪╣┘Д┘Е ╪о╪и┘К╪▒ ┘Б┘К ╪е┘Ж╪┤╪з╪б ╪з┘Д╪г╪│╪ж┘Д╪й ╪з┘Д╪к╪╣┘Д┘К┘Е┘К╪й.
┘В┘Е ╪и╪е┘Ж╪┤╪з╪б ╪г╪│╪ж┘Д╪й ┘Е╪к┘Ж┘И╪╣╪й ┘И╪┤╪з┘Е┘Д╪й ┘Е╪╣ ╪з┘Д╪е╪м╪з╪и╪з╪к ╪з┘Д┘Ж┘Е┘И╪░╪м┘К╪й.
╪к╪г┘Г╪п ┘Е┘Ж ╪к╪║╪╖┘К╪й ╪м┘Е┘К╪╣ ╪з┘Д┘Ж┘В╪з╪╖ ╪з┘Д┘Е┘З┘Е╪й ┘Б┘К ╪з┘Д┘Е╪н╪к┘И┘Й.`,
    },
    {
      role: "user",
      content: `┘В┘Е ╪и╪е┘Ж╪┤╪з╪б ${count} ╪│╪д╪з┘Д ┘Е┘Ж ╪з┘Д┘Е╪н╪к┘И┘Й ╪з┘Д╪к╪з┘Д┘К:
"${content}"

╪г┘Ж┘И╪з╪╣ ╪з┘Д╪г╪│╪ж┘Д╪й ╪з┘Д┘Е╪╖┘Д┘И╪и╪й: ${questionTypes.join("╪М ")}

┘В┘Е ╪и╪к┘Ж╪│┘К┘В ╪з┘Д╪е╪м╪з╪и╪й ╪и╪╡┘К╪║╪й JSON ┘Г╪з┘Д╪к╪з┘Д┘К:
{
  "questions": [
    {
      "type": "┘Ж┘И╪╣ ╪з┘Д╪│╪д╪з┘Д",
      "question": "┘Ж╪╡ ╪з┘Д╪│╪д╪з┘Д",
      "options": ["╪о┘К╪з╪▒ 1", "╪о┘К╪з╪▒ 2", ...], // ┘Д┘Д╪з╪о╪к┘К╪з╪▒ ┘Е┘Ж ┘Е╪к╪╣╪п╪п ┘Б┘В╪╖
      "answer": "╪з┘Д╪е╪м╪з╪и╪й ╪з┘Д╪╡╪н┘К╪н╪й",
      "explanation": "╪┤╪▒╪н ╪з┘Д╪е╪м╪з╪и╪й"
    }
  ]
}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Solve a question with step-by-step explanation
 * @param {string} question - The question to solve
 * @param {string} imageUrl - Optional image URL if question has an image
 */
export async function solveQuestion(question, imageUrl = null) {
  const content = imageUrl
    ? [
        {
          type: "text",
          text: `╪н┘Д ╪з┘Д╪│╪д╪з┘Д ╪з┘Д╪к╪з┘Д┘К ┘Е╪╣ ╪┤╪▒╪н ╪к┘Б╪╡┘К┘Д┘К ┘Д┘Д╪о╪╖┘И╪з╪к ┘И╪з┘Д┘Е╪╡╪з╪п╪▒:\n${question}`,
        },
        { type: "image_url", image_url: { url: imageUrl } },
      ]
    : `╪н┘Д ╪з┘Д╪│╪д╪з┘Д ╪з┘Д╪к╪з┘Д┘К ┘Е╪╣ ╪┤╪▒╪н ╪к┘Б╪╡┘К┘Д┘К ┘Д┘Д╪о╪╖┘И╪з╪к ┘И╪з┘Д┘Е╪╡╪з╪п╪▒:\n${question}`;

  const messages = [
    {
      role: "system",
      content: `╪г┘Ж╪к ┘Е╪╣┘Д┘Е ╪о╪и┘К╪▒ ┘Б┘К ╪н┘Д ╪з┘Д┘Е╪│╪з╪ж┘Д ┘И╪з┘Д╪г╪│╪ж┘Д╪й.
┘В┘Е ╪и╪н┘Д ╪з┘Д╪│╪д╪з┘Д ╪и╪╖╪▒┘К┘В╪й ┘Е┘Ж╪╕┘Е╪й ┘Е╪╣ ╪┤╪▒╪н ┘Г┘Д ╪о╪╖┘И╪й.
╪з╪░┘Г╪▒ ╪з┘Д┘Е╪╡╪з╪п╪▒ ┘И╪з┘Д┘В┘И╪з┘Ж┘К┘Ж ╪з┘Д┘Е╪│╪к╪о╪п┘Е╪й.
┘В╪п┘Е ╪з┘Д╪е╪м╪з╪и╪й ╪з┘Д┘Ж┘З╪з╪ж┘К╪й ╪и┘И╪╢┘И╪н.`,
    },
    {
      role: "user",
      content,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Generate mind map structure from content
 * @param {string} content - The content to create mind map from
 */
export async function generateMindMap(content) {
  const messages = [
    {
      role: "system",
      content: `╪г┘Ж╪к ╪о╪и┘К╪▒ ┘Б┘К ╪е┘Ж╪┤╪з╪б ╪з┘Д╪о╪▒╪з╪ж╪╖ ╪з┘Д╪░┘З┘Ж┘К╪й.
┘В┘Е ╪и╪к╪н┘Д┘К┘Д ╪з┘Д┘Е╪н╪к┘И┘Й ┘И╪е┘Ж╪┤╪з╪б ┘З┘К┘Г┘Д ╪о╪▒┘К╪╖╪й ╪░┘З┘Ж┘К╪й ┘Е┘Ж╪╕┘Е.`,
    },
    {
      role: "user",
      content: `┘В┘Е ╪и╪е┘Ж╪┤╪з╪б ╪о╪▒┘К╪╖╪й ╪░┘З┘Ж┘К╪й ┘Д┘Д┘Е╪н╪к┘И┘Й ╪з┘Д╪к╪з┘Д┘К:
"${content}"

┘В┘Е ╪и╪к┘Ж╪│┘К┘В ╪з┘Д╪е╪м╪з╪и╪й ╪и╪╡┘К╪║╪й JSON ┘Г╪з┘Д╪к╪з┘Д┘К:
{
  "title": "╪з┘Д╪╣┘Ж┘И╪з┘Ж ╪з┘Д╪▒╪ж┘К╪│┘К",
  "nodes": [
    {
      "id": "1",
      "label": "╪з┘Д┘Б╪▒╪╣ ╪з┘Д╪▒╪ж┘К╪│┘К",
      "children": [
        {
          "id": "1-1",
          "label": "╪з┘Д┘Б╪▒╪╣ ╪з┘Д┘Б╪▒╪╣┘К",
          "children": []
        }
      ]
    }
  ]
}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Summarize a document
 * @param {string} content - The document content
 * @param {string} type - Summary type: 'brief', 'detailed', 'bullet-points'
 */
export async function summarizeDocument(content, type = "detailed") {
  const typeInstructions = {
    brief: "┘В┘Е ╪и╪к┘Д╪о┘К╪╡ ╪з┘Д┘Е╪н╪к┘И┘Й ┘Б┘К ┘Б┘В╪▒╪й ┘И╪з╪н╪п╪й ┘Е┘И╪м╪▓╪й",
    detailed: "┘В┘Е ╪и╪к┘Д╪о┘К╪╡ ╪з┘Д┘Е╪н╪к┘И┘Й ╪и╪┤┘Г┘Д ┘Е┘Б╪╡┘Д ┘Е╪╣ ╪з┘Д╪н┘Б╪з╪╕ ╪╣┘Д┘Й ╪з┘Д╪г┘Б┘Г╪з╪▒ ╪з┘Д╪▒╪ж┘К╪│┘К╪й",
    "bullet-points": "┘В┘Е ╪и╪к┘Д╪о┘К╪╡ ╪з┘Д┘Е╪н╪к┘И┘Й ╪╣┘Д┘Й ╪┤┘Г┘Д ┘Ж┘В╪з╪╖ ╪▒╪ж┘К╪│┘К╪й",
  };

  const messages = [
    {
      role: "system",
      content: "╪г┘Ж╪к ╪о╪и┘К╪▒ ┘Б┘К ╪к┘Д╪о┘К╪╡ ╪з┘Д┘Е╪н╪к┘И┘Й ╪з┘Д╪г┘Г╪з╪п┘К┘Е┘К ┘И╪з┘Д╪╣┘Д┘Е┘К ╪и╪з┘Д┘Д╪║╪й ╪з┘Д╪╣╪▒╪и┘К╪й.",
    },
    {
      role: "user",
      content: `${
        typeInstructions[type] || typeInstructions.detailed
      }:\n\n${content}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Generate presentation slides
 * @param {string} content - The content to create presentation from
 * @param {number} slideCount - Number of slides to generate
 */
export async function generatePresentation(content, slideCount = 10) {
  const messages = [
    {
      role: "system",
      content: `╪г┘Ж╪к ╪о╪и┘К╪▒ ┘Б┘К ╪е┘Ж╪┤╪з╪б ╪з┘Д╪╣╪▒┘И╪╢ ╪з┘Д╪к┘В╪п┘К┘Е┘К╪й ╪з┘Д╪з╪н╪к╪▒╪з┘Б┘К╪й.
┘В┘Е ╪и╪е┘Ж╪┤╪з╪б ╪┤╪▒╪з╪ж╪н ╪╣╪▒╪╢ ┘Е┘Ж╪╕┘Е╪й ┘И╪м╪░╪з╪и╪й.`,
    },
    {
      role: "user",
      content: `┘В┘Е ╪и╪е┘Ж╪┤╪з╪б ╪╣╪▒╪╢ ╪к┘В╪п┘К┘Е┘К ┘Е┘Ж ${slideCount} ╪┤╪▒┘К╪н╪й ┘Д┘Д┘Е╪н╪к┘И┘Й ╪з┘Д╪к╪з┘Д┘К:
"${content}"

┘В┘Е ╪и╪к┘Ж╪│┘К┘В ╪з┘Д╪е╪м╪з╪и╪й ╪и╪╡┘К╪║╪й JSON ┘Г╪з┘Д╪к╪з┘Д┘К:
{
  "title": "╪╣┘Ж┘И╪з┘Ж ╪з┘Д╪╣╪▒╪╢",
  "slides": [
    {
      "title": "╪╣┘Ж┘И╪з┘Ж ╪з┘Д╪┤╪▒┘К╪н╪й",
      "content": ["┘Ж┘В╪╖╪й 1", "┘Ж┘В╪╖╪й 2", ...],
      "notes": "┘Е┘Д╪з╪н╪╕╪з╪к ┘Д┘Д┘Е┘В╪п┘Е"
    }
  ]
}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

export default {
  chatCompletion,
  streamChatCompletion,
  generateImage,
  analyzeImage,
  generateResearchPaper,
  generateQuestions,
  solveQuestion,
  generateMindMap,
  summarizeDocument,
  generatePresentation,
};
