/**
 * AIML API Service
 * Provides integration with AIML API for AI-powered features
 */

const API_URL =
  import.meta.env.VITE_AIML_API_URL || "https://api.aimlapi.com/v1";
const API_KEY =
  import.meta.env.VITE_AIML_API_KEY || "24846e8f3bce499aaf46ae76bb75f388";

/**
 * Make a chat completion request
 * @param {Array} messages - Array of message objects with role and content
 * @param {Object} options - Additional options like model, temperature, etc.
 */
export async function chatCompletion(messages, options = {}) {
  try {
    const response = await fetch(`${API_URL}/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${API_KEY}`,
      },
      body: JSON.stringify({
        model: options.model || "openai/gpt-5-nano-2025-08-07",
        messages,
        temperature: options.temperature || 0.7,
        max_tokens: options.maxTokens || 4096,
        ...options,
      }),
    });

    if (!response.ok) {
      let errorMessage = "AI API request failed";
      try {
        const error = await response.json();
        errorMessage = error.error?.message || error.message || errorMessage;
      } catch (e) {
        errorMessage = `HTTP ${response.status}: ${response.statusText}`;
      }
      throw new Error(errorMessage);
    }

    return response.json();
  } catch (error) {
    console.error("Error in chatCompletion:", error);
    throw error;
  }
}

/**
 * Stream chat completion for real-time responses
 * @param {Array} messages - Array of message objects
 * @param {Function} onChunk - Callback for each streamed chunk
 * @param {Object} options - Additional options
 */
export async function streamChatCompletion(messages, onChunk, options = {}) {
  const response = await fetch(`${API_URL}/chat/completions`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${API_KEY}`,
    },
    body: JSON.stringify({
      model: options.model || "openai/gpt-5-nano-2025-08-07",
      messages,
      temperature: options.temperature || 0.7,
      max_tokens: options.maxTokens || 4096,
      stream: true,
      ...options,
    }),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message || "AI API request failed");
  }

  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = "";

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split("\n");
    buffer = lines.pop() || "";

    for (const line of lines) {
      if (line.startsWith("data: ")) {
        const data = line.slice(6);
        if (data === "[DONE]") return;
        try {
          const parsed = JSON.parse(data);
          const content = parsed.choices?.[0]?.delta?.content;
          if (content) onChunk(content);
        } catch (e) {
          // Skip invalid JSON
        }
      }
    }
  }
}

/**
 * Generate an image using AI
 * @param {string} prompt - The image generation prompt
 * @param {Object} options - Additional options like size, model, etc.
 */
export async function generateImage(prompt, options = {}) {
  const response = await fetch(`${API_URL}/images/generations`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${API_KEY}`,
    },
    body: JSON.stringify({
      model: options.model || "dall-e-3",
      prompt,
      n: options.n || 1,
      size: options.size || "1024x1024",
      ...options,
    }),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.message || "Image generation failed");
  }

  return response.json();
}

/**
 * Analyze an image and get description
 * @param {string} imageUrl - URL or base64 of the image
 * @param {string} prompt - What to analyze about the image
 */
export async function analyzeImage(
  imageUrl,
  prompt = "ÙˆØµÙ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„ØªÙØµÙŠÙ„"
) {
  const messages = [
    {
      role: "user",
      content: [
        { type: "text", text: prompt },
        { type: "image_url", image_url: { url: imageUrl } },
      ],
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Generate research paper content using GPT-5 Nano
 * @param {string} topic - The research topic
 * @param {string} researcherName - Researcher name
 * @param {string} supervisorName - Supervisor name
 * @param {Array} sections - Sections to include (checked options)
 * @param {string} userMessage - Additional user instructions from chat
 * @param {Object} options - Additional options
 */
export async function generateResearchPaper(
  topic,
  researcherName = "",
  supervisorName = "",
  sections = [],
  userMessage = "",
  options = {}
) {
  // Build concise sections list
  const sectionsList =
    sections.length > 0
      ? sections.join("ØŒ ")
      : "Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©ØŒ ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŒ Ø§Ù„Ù…Ù„Ø®ØµØŒ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ©ØŒ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ Ø§Ù„Ø®Ø§ØªÙ…Ø©ØŒ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹";

  // Build optimized prompt - concise but complete
  let userPrompt = `Ù…ÙˆØ¶ÙˆØ¹: "${topic}"\n`;
  if (researcherName) userPrompt += `Ø¨Ø§Ø­Ø«: ${researcherName}\n`;
  if (supervisorName) userPrompt += `Ù…Ø´Ø±Ù: ${supervisorName}\n`;
  userPrompt += `Ø£Ù‚Ø³Ø§Ù…: ${sectionsList}\n`;
  if (userMessage) userPrompt += `Ù…Ù„Ø§Ø­Ø¸Ø§Øª: ${userMessage}\n`;

  const messages = [
    {
      role: "system",
      content: `Ø£Ù†Øª Ø¨Ø§Ø­Ø« Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ù…ØªØ®ØµØµ. Ø§ÙƒØªØ¨ Ø¨Ø­Ø«Ø§Ù‹ Ø¹Ù„Ù…ÙŠØ§Ù‹ ÙƒØ§Ù…Ù„Ø§Ù‹ Ø¨Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© Ø±ØµÙŠÙ†Ø© ÙˆÙ…Ø¹Ø§ÙŠÙŠØ± Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©.

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹:
- Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·
- Ù„Ø§ ØªÙƒØªØ¨ Ø£ÙŠ Ø£ÙƒÙˆØ§Ø¯ LaTeX Ø£Ùˆ HTML Ø£Ùˆ Ø£ÙŠ Ù„ØºØ© Ø¨Ø±Ù…Ø¬Ø©
- Ù„Ø§ ØªÙƒØªØ¨ Ø£ÙŠ ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªÙ†ÙÙŠØ° Ø£Ùˆ Ø¥Ø±Ø´Ø§Ø¯Ø§Øª
- Ù„Ø§ ØªÙƒØªØ¨ Ø£ÙŠ Ù…Ù„Ø§Ø­Ø¸Ø§Øª ØªÙ…Ù‡ÙŠØ¯ÙŠØ© Ø£Ùˆ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
- Ø§Ø¨Ø¯Ø£ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¨Ø­Ø« Ø«Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰
- Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ Ù†ØµÙŠ Ø¨Ø³ÙŠØ· Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·
- Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ Ø´ÙŠØ¡ Ø¹Ù† Ø§Ù„Ø®Ø·ÙˆØ· Ø£Ùˆ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø£Ùˆ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚`,
    },
    {
      role: "user",
      content: userPrompt,
    },
  ];

  const response = await chatCompletion(messages, {
    model: options.model || "openai/gpt-5-nano-2025-08-07",
    maxTokens: options.maxTokens || 8000, // Reduced from 12000 for efficiency
    temperature: options.temperature || 0.7,
  });

  // Log token usage for monitoring
  if (response.usage) {
    console.log("ğŸ“Š Token Usage:", {
      prompt: response.usage.prompt_tokens,
      completion: response.usage.completion_tokens,
      total: response.usage.total_tokens,
      cost: `${(response.usage.total_tokens * 0.000001).toFixed(6)} credits`, // Approximate
    });
  }

  return response;
}

/**
 * Generate questions from content
 * @param {string} content - The content to generate questions from
 * @param {Object} options - Question generation options
 */
export async function generateQuestions(content, options = {}) {
  const questionTypes = options.types || [
    "Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯",
    "ØµØ­ ÙˆØ®Ø·Ø£",
    "Ø£Ø³Ø¦Ù„Ø© Ù…Ù‚Ø§Ù„ÙŠØ©",
  ];
  const count = options.count || 10;

  const messages = [
    {
      role: "system",
      content: `Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©.
Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ù…ØªÙ†ÙˆØ¹Ø© ÙˆØ´Ø§Ù…Ù„Ø© Ù…Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ©.
ØªØ£ÙƒØ¯ Ù…Ù† ØªØºØ·ÙŠØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.`,
    },
    {
      role: "user",
      content: `Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ${count} Ø³Ø¤Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ:
"${content}"

Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: ${questionTypes.join("ØŒ ")}

Ù‚Ù… Ø¨ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON ÙƒØ§Ù„ØªØ§Ù„ÙŠ:
{
  "questions": [
    {
      "type": "Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„",
      "question": "Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„",
      "options": ["Ø®ÙŠØ§Ø± 1", "Ø®ÙŠØ§Ø± 2", ...], // Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ù…ØªØ¹Ø¯Ø¯ ÙÙ‚Ø·
      "answer": "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©",
      "explanation": "Ø´Ø±Ø­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"
    }
  ]
}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Solve a question with step-by-step explanation
 * @param {string} question - The question to solve
 * @param {string} imageUrl - Optional image URL if question has an image
 */
export async function solveQuestion(question, imageUrl = null) {
  const content = imageUrl
    ? [
        {
          type: "text",
          text: `Ø­Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ø¹ Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ø®Ø·ÙˆØ§Øª ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø±:\n${question}`,
        },
        { type: "image_url", image_url: { url: imageUrl } },
      ]
    : `Ø­Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ø¹ Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ø®Ø·ÙˆØ§Øª ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø±:\n${question}`;

  const messages = [
    {
      role: "system",
      content: `Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø®Ø¨ÙŠØ± ÙÙŠ Ø­Ù„ Ø§Ù„Ù…Ø³Ø§Ø¦Ù„ ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø©.
Ù‚Ù… Ø¨Ø­Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø¸Ù…Ø© Ù…Ø¹ Ø´Ø±Ø­ ÙƒÙ„ Ø®Ø·ÙˆØ©.
Ø§Ø°ÙƒØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆØ§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©.
Ù‚Ø¯Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙˆØ¶ÙˆØ­.`,
    },
    {
      role: "user",
      content,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Generate mind map structure from content
 * @param {string} content - The content to create mind map from
 */
export async function generateMindMap(content) {
  const messages = [
    {
      role: "system",
      content: `Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø±Ø§Ø¦Ø· Ø§Ù„Ø°Ù‡Ù†ÙŠØ©.
Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ù…Ù†Ø¸Ù….`,
    },
    {
      role: "user",
      content: `Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ© Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ:
"${content}"

Ù‚Ù… Ø¨ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON ÙƒØ§Ù„ØªØ§Ù„ÙŠ:
{
  "title": "Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ",
  "nodes": [
    {
      "id": "1",
      "label": "Ø§Ù„ÙØ±Ø¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ",
      "children": [
        {
          "id": "1-1",
          "label": "Ø§Ù„ÙØ±Ø¹ Ø§Ù„ÙØ±Ø¹ÙŠ",
          "children": []
        }
      ]
    }
  ]
}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Summarize a document
 * @param {string} content - The document content
 * @param {string} type - Summary type: 'brief', 'detailed', 'bullet-points'
 */
export async function summarizeDocument(content, type = "detailed") {
  const typeInstructions = {
    brief: "Ù‚Ù… Ø¨ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙÙŠ ÙÙ‚Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…ÙˆØ¬Ø²Ø©",
    detailed: "Ù‚Ù… Ø¨ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø´ÙƒÙ„ Ù…ÙØµÙ„ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
    "bullet-points": "Ù‚Ù… Ø¨ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©",
  };

  const messages = [
    {
      role: "system",
      content: "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ ÙˆØ§Ù„Ø¹Ù„Ù…ÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
    },
    {
      role: "user",
      content: `${
        typeInstructions[type] || typeInstructions.detailed
      }:\n\n${content}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

/**
 * Generate presentation slides
 * @param {string} content - The content to create presentation from
 * @param {number} slideCount - Number of slides to generate
 */
export async function generatePresentation(content, slideCount = 10) {
  const messages = [
    {
      role: "system",
      content: `Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠØ© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©.
Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø´Ø±Ø§Ø¦Ø­ Ø¹Ø±Ø¶ Ù…Ù†Ø¸Ù…Ø© ÙˆØ¬Ø°Ø§Ø¨Ø©.`,
    },
    {
      role: "user",
      content: `Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø±Ø¶ ØªÙ‚Ø¯ÙŠÙ…ÙŠ Ù…Ù† ${slideCount} Ø´Ø±ÙŠØ­Ø© Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ:
"${content}"

Ù‚Ù… Ø¨ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON ÙƒØ§Ù„ØªØ§Ù„ÙŠ:
{
  "title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¹Ø±Ø¶",
  "slides": [
    {
      "title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø´Ø±ÙŠØ­Ø©",
      "content": ["Ù†Ù‚Ø·Ø© 1", "Ù†Ù‚Ø·Ø© 2", ...],
      "notes": "Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù„Ù„Ù…Ù‚Ø¯Ù…"
    }
  ]
}`,
    },
  ];

  return chatCompletion(messages, { model: "gpt-4o" });
}

export default {
  chatCompletion,
  streamChatCompletion,
  generateImage,
  analyzeImage,
  generateResearchPaper,
  generateQuestions,
  solveQuestion,
  generateMindMap,
  summarizeDocument,
  generatePresentation,
};
